================================================================================  
GeminiCli API 测试
================================================================================  

================================================================================  
【测试1】流式请求 (stream_request with native=False)
================================================================================  
请求体: {
  "model": "gemini-2.5-flash",
  "request": {
    "contents": [
      {
        "role": "user",
        "parts": [
          {
            "text": "Hello, tell me a joke in one sentence."
          }
        ]
      }
    ]
  }
}

流式响应数据 (每个chunk):
--------------------------------------------------------------------------------  
[2026-01-10 09:55:29] [INFO] SQLite storage initialized at ./creds\credentials.db 
[2026-01-10 09:55:29] [INFO] Using SQLite storage backend
[2026-01-10 09:55:31] [INFO] Token刷新成 功并已保存: my-project-9-481103-1765596755.json (mode=geminicli)
[2026-01-10 09:55:34] [INFO] [DB] 准备commit，总更新行数=1
[2026-01-10 09:55:34] [INFO] [DB] commit 完成
[2026-01-10 09:55:34] [INFO] [DB] update_credential_state 结束: success=True, updated_count=1

Chunk #1:
  类型: str
  长度: 626
  内容预览: 'data: {"response": {"candidates": [{"content": {"role": "model","parts": [{"text": "Why did the scarecrow win an award? Because he was outstanding in his field."}]},"finishReason": "STOP"}],"usageMeta'
  解析后的JSON: {
    "response": {
        "candidates": [
            {
                "content": {
                    "role": "model",     
                    "parts": [
                        {
                            "text": "Why did the scarecrow win an award? Because he was outstanding in his field."
                        }
                    ]
                },
                "finishReason": "STOP"   
            }
        ],
        "usageMetadata": {
            "promptTokenCount": 10,      
            "candidatesTokenCount": 17,  
            "totalTokenCount": 51,       
            "trafficType": "PROVISIONED_THROUGHPUT",
            "promptTokensDetails": [     
                {
                    "modality": "TEXT",  
                    "tokenCount": 10     
                }
            ],
            "candidatesTokensDetails": [ 
                {
                    "modality": "TEXT",  
                    "tokenCount": 17     
                }
            ],
            "thoughtsTokenCount": 24     
        },
        "modelVersion": "gemini-2.5-flash",
        "createTime": "2026-01-10T01:55:29.168589Z",
        "responseId": "kbFhaY2lCr-ZseMPqMiDmAU"
    },
    "traceId": "55650653afd3c738"        
}

Chunk #2:
  类型: str
  长度: 0
  内容预览: ''
E:\projects\gcli2api\src\api\geminicli.py:491: RuntimeWarning: coroutine 'get_auto_ban_error_codes' was never awaited      
  async for chunk in stream_request(body=test_body, native=False):
RuntimeWarning: Enable tracemalloc to get the object allocation traceback

总共收到 2 个chunk

================================================================================  
【测试2】非流式请求 (non_stream_request) 
================================================================================  
请求体: {
  "model": "gemini-2.5-flash",
  "request": {
    "contents": [
      {
        "role": "user",
        "parts": [
          {
            "text": "Hello, tell me a joke in one sentence."
          }
        ]
      }
    ]
  }
}

[2026-01-10 09:55:35] [INFO] Token刷新成 功并已保存: gen-lang-client-0194852792-1767296759.json (mode=geminicli)
[2026-01-10 09:55:38] [INFO] [DB] 准备commit，总更新行数=1
[2026-01-10 09:55:38] [INFO] [DB] commit 完成
[2026-01-10 09:55:38] [INFO] [DB] update_credential_state 结束: success=True, updated_count=1
E:\projects\gcli2api\src\api\geminicli.py:530: RuntimeWarning: coroutine 'get_auto_ban_error_codes' was never awaited      
  response = await non_stream_request(body=test_body)
RuntimeWarning: Enable tracemalloc to get the object allocation traceback
非流式响应数据:
--------------------------------------------------------------------------------  
状态码: 200
Content-Type: application/json; charset=UTF-8

响应头: {'server': 'openresty', 'date': 'Sat, 10 Jan 2026 01:55:34 GMT', 'content-type': 'application/json; charset=UTF-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'x-cloudaicompanion-trace-id': 'bf3a5eb6636774d2', 'vary': 'Origin, X-Origin, Referer', 'content-encoding': 'gzip', 'x-xss-protection': '0', 'x-frame-options': 'SAMEORIGIN', 'x-content-type-options': 'nosniff', 'server-timing': 'gfet4t7; dur=1377', 'alt-svc': 'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000', 'access-control-allow-origin': '*', 'access-control-allow-methods': 'GET, POST, PUT, DELETE, PATCH, OPTIONS', 'access-control-allow-headers': 'Content-Type, Authorization, X-Requested-With', 'cache-control': 'no-cache', 'content-length': '969'}

响应内容 (原始):
{
  "response": {
    "candidates": [
      {
        "content": {
          "role": "model",
          "parts": [
            {
              "text": "Why did the scarecrow win an award? Because he was outstanding in his field!"
            }
          ]
        },
        "finishReason": "STOP",
        "avgLogprobs": -0.54438119776108684
      }
    ],
    "usageMetadata": {
      "promptTokenCount": 10,
      "candidatesTokenCount": 17,        
      "totalTokenCount": 47,
      "trafficType": "PROVISIONED_THROUGHPUT",
      "promptTokensDetails": [
        {
          "modality": "TEXT",
          "tokenCount": 10
        }
      ],
      "candidatesTokensDetails": [       
        {
          "modality": "TEXT",
          "tokenCount": 17
        }
      ],
      "thoughtsTokenCount": 20
    },
    "modelVersion": "gemini-2.5-flash",  
    "createTime": "2026-01-10T01:55:33.450396Z",
    "responseId": "lbFhady-G7yi694PmLOP4As"
  },
  "traceId": "bf3a5eb6636774d2"
}


响应内容 (格式化JSON):
{
  "response": {
    "candidates": [
      {
        "content": {
          "role": "model",
          "parts": [
            {
              "text": "Why did the scarecrow win an award? Because he was outstanding in his field!"
            }
          ]
        },
        "finishReason": "STOP",
        "avgLogprobs": -0.5443811977610868
      }
    ],
    "usageMetadata": {
      "promptTokenCount": 10,
      "candidatesTokenCount": 17,        
      "totalTokenCount": 47,
      "trafficType": "PROVISIONED_THROUGHPUT",
      "promptTokensDetails": [
        {
          "modality": "TEXT",
          "tokenCount": 10
        }
      ],
      "candidatesTokensDetails": [       
        {
          "modality": "TEXT",
          "tokenCount": 17
        }
      ],
      "thoughtsTokenCount": 20
    },
    "modelVersion": "gemini-2.5-flash",  
    "createTime": "2026-01-10T01:55:33.450396Z",
    "responseId": "lbFhady-G7yi694PmLOP4As"
  },
  "traceId": "bf3a5eb6636774d2"
}

================================================================================  
测试完成
================================================================================ 